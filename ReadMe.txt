SeqToSeq:
聊天机器人：
编码器RNN一次迭代输入语句一个标记（例如字），在每个时间步输出一个“输出”向量和一个“隐藏状态”向量。然后将隐藏状态向量传递到下一个时间步骤，同时记录输出向量。编码器将序列中每个点上看到的上下文转换为高维空间中的一组点，解码器将使用这些点为给定任务生成有意义的输出。

解码器RNN以令牌方式生成响应语句。它使用编码器的上下文向量和内部隐藏状态来生成序列中的下一个单词。它继续生成单词，直到输出一个eos_标记，表示句子的结尾。我们在解码器中使用注意机制来帮助它在生成输出时“注意”输入的某些部分。对于我们的模型，我们实现了Luong等人的“全局关注”模块，并将其用作解码模型中的子模块。

由于这块涉及到文本，所以不深入考虑：

https://pytorch.org/tutorials/beginner/deploy_seq2seq_hybrid_frontend_tutorial.html
详细请查看上面的网站。
